- name: Dockerhost on oracle (oci)
  hosts: localhost
  connection: local
  collections:
    - oracle.oci
    - community.docker
  gather_facts: true
  become: true
  become_user: root
  tasks:

    - name: Capture start time
      set_fact:
        start_time: "{{ ansible_facts['date_time']['iso8601'] }}"

    - name: Display start time
      debug:
        msg: "Playbook started at {{ start_time }}"

    - name: Check swap file exists
      ansible.builtin.stat:
        path: "/{{ project_directory }}/swap.file"
      register: swap_file

    - name: Create swap file if not exists
      ansible.builtin.shell: |
        dd if=/dev/zero of=/"{{ project_directory }}"/swap.file bs=1024 count=1048576
        mkswap /"{{ project_directory }}"/swap.file
      when:
        - not swap_file.stat.exists
        - ansible_facts["swaptotal_mb"] < 1

    - name: Set swap file permissions
      ansible.builtin.file:
        path: "/{{ project_directory }}/swap.file"
        state: file
        owner: root
        group: root
        mode: '0600'
      when:
        - ansible_facts["swaptotal_mb"] < 1

    - name: Set swap mount
      ansible.posix.mount:
        src: /"{{ project_directory }}"/swap.file
        path: none
        fstype: swap
        opts: sw
        passno: '0'
        dump: '0'
        state: present
      when:
        - ansible_facts["swaptotal_mb"] < 1

    - name: Mount swap now
      ansible.builtin.shell: |
        swapon /"{{ project_directory }}"/swap.file
      when:
        - ansible_facts["swaptotal_mb"] < 1

    - name: APT Required packages
      ansible.builtin.apt:
        pkg:
          - docker.io
          # - libcap2-bin
          - python3-pip
          # - ssl-cert
          - docker-compose-v2
          - fuse3
        state: latest
        update_cache: true

    # Install a snap with classic confinement
    # sudo snap install oracle-cloud-agent --classic
    - name: Install "oracle-cloud-agent" with option --classic
      snap:
        name: oracle-cloud-agent
        classic: yes

    - name: Docker python packages
      ansible.builtin.pip:
        name:
          - docker
          - oci
        executable: pip3
        break_system_packages: true
        state: latest

    - name: IP Forwarding enable/persist
      ansible.builtin.sysctl:
        name: net.ipv4.ip_forward
        value: '1'
        state: present
        reload: true
        sysctl_set: true
        sysctl_file: /etc/sysctl.conf

    - name: Docker service started/enabled
      ansible.builtin.systemd:
        name: docker
        state: started
        enabled: true

    - name: fetch decrypt External S3 key
      oci_key_management_decrypted_data:
        auth_type: "instance_principal"
        ciphertext: "{{ objectstore_s3_key_cipher }}"
        service_endpoint: "{{ oci_kms_endpoint }}"
        key_id: "{{ oci_kms_keyid }}"
      register: OBJECTSTORE_S3_KEY_decrypt
      tags:
        - bucket

    - name: fetch decrypt External S3 secret
      oci_key_management_decrypted_data:
        auth_type: "instance_principal"
        ciphertext: "{{ objectstore_s3_secret_cipher }}"
        service_endpoint: "{{ oci_kms_endpoint }}"
        key_id: "{{ oci_kms_keyid }}"
      register: OBJECTSTORE_S3_SECRET_decrypt
      tags:
        - bucket
  
# ------------Docker Rclone Plugin Configuration---------
    # Adapted from https://rclone.org/docker/
    # and https://www.selfhosted.club/posts/s3-backed-docker-volumes/
    - name: Create rclone plugin directories
      ansible.builtin.file:
        path: "{{ item }}"
        state: directory
        owner: root
        group: root
        mode: '0755'
      with_items:
        - /var/lib/docker-plugins/rclone/config
        - /var/lib/docker-plugins/rclone/cache

    - name: Create rclone config file
      ansible.builtin.copy:
        dest: /var/lib/docker-plugins/rclone/config/rclone.conf
        content: |
          [mega]
          type = s3
          provider = Other
          access_key_id = {{ OBJECTSTORE_S3_KEY_decrypt.decrypted_data.plaintext | b64decode  }}
          secret_access_key = {{ OBJECTSTORE_S3_SECRET_decrypt.decrypted_data.plaintext | b64decode  }}
          region = {{ objectstore_s3_region }}
          endpoint = {{ objectstore_s3_hostname }}
          acl = private
          bucket_acl = private

        owner: root
        group: root
        mode: '0600'

    - name: Clear rclone cache directory
      ansible.builtin.file:
        path: /var/lib/docker-plugins/rclone/cache
        state: absent

    - name: Install Rclone Docker plugin
      community.docker.docker_plugin:
        plugin_name: rclone/docker-volume-rclone:latest
        alias: rclone
        state: present
        install_options:
          grant_all_permissions: true
        plugin_options:
          args: "-v"

    - name: Enable Docker Rclone Plugin
      community.docker.docker_plugin:
        name: rclone
        enabled: true
        state: present
# --------------------------------

    - name: Various container directories - application
      ansible.builtin.file:
        path: "{{ item }}"
        state: directory
        owner: ubuntu
        mode: '0750'
      with_items:
        - "{{ project_directory }}"
        - "{{ project_directory }}/git"
        - "{{ project_directory }}/mount"
        

    - name: fetch decrypt Zerotier VPN Network
      oci_key_management_decrypted_data:
        auth_type: "instance_principal"
        ciphertext: "{{ zerotier_ntwk_cipher }}"
        service_endpoint: "{{ oci_kms_endpoint }}"
        key_id: "{{ oci_kms_keyid }}"
      register: zerotier_ntwk_decrypt

    - name: fetch decrypt Zerotier VPN Token
      oci_key_management_decrypted_data:
        auth_type: "instance_principal"
        ciphertext: "{{ zerotier_token_cipher }}"
        service_endpoint: "{{ oci_kms_endpoint }}"
        key_id: "{{ oci_kms_keyid }}"
      register: zerotier_token_decrypt

    - name: fetch decrypt Extra Github URL (private access)
      oci_key_management_decrypted_data:
        auth_type: "instance_principal"
        ciphertext: "{{ github_cipher }}"
        service_endpoint: "{{ oci_kms_endpoint }}"
        key_id: "{{ oci_kms_keyid }}"
      register: github_decrypt

# ------BACKUP BUCKET CREATION--------
    - name: Create S3 bucket (primary storage)
      # become: true
      amazon.aws.s3_bucket:
        state: present
        aws_access_key: '{{ OBJECTSTORE_S3_KEY_decrypt.decrypted_data.plaintext | b64decode | trim }}'
        aws_secret_key: '{{ OBJECTSTORE_S3_SECRET_decrypt.decrypted_data.plaintext | b64decode | trim }}'
        endpoint_url: 'https://{{ objectstore_s3_hostname }}'
        region: '{{ objectstore_s3_region }}' 
        name: '{{ objectstore_s3_bucketname }}' 
        acl: private
      tags:
        - bucket

# -------Restore Backup---------
    - name: Determine Mount folder state via one of its subdirs (zerotier-one)
      ansible.builtin.stat:
        path: "{{ project_directory }}/mount/zerotier-one"
      register: zerotier_state

    - name: Get backup from storage if exists
      amazon.aws.s3_object:
        aws_access_key: '{{ OBJECTSTORE_S3_KEY_decrypt.decrypted_data.plaintext | b64decode | trim }}'
        aws_secret_key: '{{ OBJECTSTORE_S3_SECRET_decrypt.decrypted_data.plaintext | b64decode | trim }}'
        endpoint_url: 'https://{{ objectstore_s3_hostname }}'
        region: '{{ objectstore_s3_region }}' 
        name: '{{ objectstore_s3_bucketname }}' 
        mode: get
        object: "mount_backup.tar.gz"
        dest: "{{ project_directory }}/mount_backup.tar.gz"
      when: not zerotier_state.stat.exists
      ignore_errors: true

    - name: Unarchive backup if dir not exists
      ansible.builtin.unarchive:
        src: "{{ project_directory }}/mount_backup.tar.gz"
        dest: "{{ project_directory }}/"
        remote_src: true
      when: not zerotier_state.stat.exists
      ignore_errors: true

# --------------------------------

    - name: Determine scripts repo state
      ansible.builtin.stat:
        path: "{{ project_directory }}/git/scripts"
      register: scripts_repo_state

    - name: Clone a secondary repo for specialised customizations (scripts)
      ansible.builtin.shell: "{{ item }}"
      with_items:
        git -C {{ project_directory }}/git/ clone -q {{ github_decrypt.decrypted_data.plaintext | b64decode  }}
      tags: custom
      when: not scripts_repo_state.stat.exists
      # ignore_errors: true

# -------DOCKER CONTAINERS---------
    - name: Docker network
      community.docker.docker_network:
        name: oci-dockerserver-ntwrk
        driver: bridge
        ipam_config:
          - subnet: "{{ docker_network }}/24"
            gateway: "{{ docker_gw }}"
    
    # Configure a VPN client
    - name: Zerotier container VPN
      community.docker.docker_container:
        name: zerotier_vpn
        hostname: zerotiervpn
        image: zerotier/zerotier:latest
        devices:
          - /dev/net/tun
        network_mode: host
        # env:
        #   ZEROTIER_API_SECRET: "{{ zerotier_token_decrypt.decrypted_data.plaintext | b64decode  }}"
        # command: "{{ zerotier_ntwk_decrypt.decrypted_data.plaintext | b64decode  }}"
        capabilities:
          - NET_ADMIN
          - SYS_ADMIN
          - CAP_SYS_RAWIO
        volumes:
          - "/{{ project_directory }}/mount/zerotier-one:/var/lib/zerotier-one"
        pull: true
        # purge_networks: true
        restart_policy: "always"
        container_default_behavior: "compatibility"
      no_log: false
      ignore_errors: true
      tags:
        - basicservices

    - name: Portainer container (Docker Management)
      community.docker.docker_container:
        name: portainer
        hostname: portainer
        image: portainer/portainer-ee:latest
        networks:
          - name: oci-dockerserver-ntwrk
            ipv4_address: "{{ docker_portainer }}"
        ports:
          - 8000:8000
          - 9000:9000
          - 9443:9443
        volumes:
          - /var/run/docker.sock:/var/run/docker.sock
          - /var/lib/docker/volumes:/var/lib/docker/volumes
          - /:/host
          - "/{{ project_directory }}/mount/portainer_data:/data" 
        pull: true
        restart_policy: "always"
        container_default_behavior: "compatibility"
      no_log: true
      tags:
        - basicservices

    - name: Portainer agent container (Docker Management)
      community.docker.docker_container:
        name: portainer_agent
        hostname: portaineragent
        image: portainer/agent:latest
        ports:
          - 9001:9001
        volumes:
          - /var/run/docker.sock:/var/run/docker.sock
          - /var/lib/docker/volumes:/var/lib/docker/volumes
          - /:/host
        pull: true
        restart_policy: "always"
        container_default_behavior: "compatibility"
      no_log: true
      tags:
        - basicservices

    - name: watchtower container (automatic updates)
      community.docker.docker_container:
        name: watchtower
        hostname: watchtower
        image: containrrr/watchtower
        volumes:
          - /var/run/docker.sock:/var/run/docker.sock
        networks:
          - name: oci-dockerserver-ntwrk
            ipv4_address: "{{ docker_watchtower }}"
        env:
          WATCHTOWER_CLEANUP: "true"
          TZ: Australia/Brisbane
          # WATCHTOWER_POLL_INTERVAL: 21600  # 6 hours
          # https://pkg.go.dev/github.com/robfig/cron@v1.2.0#hdr-CRON_Expression_Format
          WATCHTOWER_SCHEDULE: "0 0 22 * * 5"
          # WATCHTOWER_NOTIFICATION_REPORT: "true"
          # WATCHTOWER_NOTIFICATION_URL: >
        pull: true
        restart_policy: "unless-stopped"
        container_default_behavior: "compatibility"
      no_log: true
      tags:
        - basicservices

    - name: Cloudflare Container
      community.docker.docker_container:
        name: dockerhost_tunnel
        hostname: dockerhost_tunnel
        image: cloudflare/cloudflared:latest
        networks:
          - name: oci-dockerserver-ntwrk
            ipv4_address: "{{ docker_cloudflare_tunnel }}"
        # env:
        command: "tunnel --no-autoupdate run --token {{ dns_token }}"
        # entrypoint: "cloudflared --no-autoupdate"
        pull: true
        # purge_networks: true
        restart_policy: "always"
        container_default_behavior: "compatibility"
      no_log: true
      tags:
        - cloudflare

    - name: Join Zerotier Network
      ansible.builtin.shell:
        cmd: "docker exec zerotier_vpn zerotier-cli join {{ zerotier_ntwk_decrypt.decrypted_data.plaintext | b64decode  }}"
      args:
        executable: /bin/bash
      tags:
        - basicservices

    # # Docker compose builds
    # - name: Start services using Docker Compose (Basic Services)
    #   community.docker.docker_compose_v2:
    #     project_src: "{{ project_directory }}/git/scripts/docker/cloud/basicservices/docker-compose.yaml"
    #     state: present  # Options: present, absent, restarted

    - name: Ansible Manual replay script (set)
      ansible.builtin.lineinfile:
        path: "{{ project_directory }}/ansible_replay.sh"
        create: true
        owner: root
        group: root
        mode: '0500'
        line: "{{ item }}"
      no_log: true
      with_items:
        - "#!/bin/bash"
        - "# Replay Ansilbe playbook"
        - "# Change to directory"
        - "cd {{ project_directory }}/git/oci-dockerhost"
        - "# Ensure up-to-date"
        - "git pull"
        - "# Execute playbook"
        - "ansible-playbook dockerhost_playbook.yml --extra-vars '@{{ project_directory }}/dockerhost-vars.yaml'"

# -----Backup---------
    - name: mount backup playbook (clear)
      ansible.builtin.file:
        path: "{{ project_directory }}/mount-backup.yml"
        state: absent

    - name: mount backup playbook (set)
      ansible.builtin.lineinfile:
        path: "{{ project_directory }}/mount-backup.yml"
        create: true
        owner: root
        group: root
        mode: '0640'
        line: "{{ item }}"
      with_items:
        - "---"
        - "- name: mount-backup.yml"
        - "  hosts: localhost"
        - "  gather_facts: false"
        - "  collections:"
        - "    - oracle.oci"
        - "  tasks:"
        - "  "
        - "    - name: Archive mount folder locally"
        - "      archive:"
        - "        path: \"{{ project_directory }}/{{ '{{ item }}' }}\""
        - "        dest: \"{{ project_directory }}/{{ '{{ item }}' }}_backup.tar.gz\""
        - "        format: gz"
        - "        owner: root"
        - "        group: root"
        - "        mode: '0640'"
        - "        exclude:"
        - "          - \"{{ project_directory }}/mount/qBitTorrent/downloads\""
        - "      with_items:"
        - "        - mount"
        - "   "
        - "    - name: Upload mount archive to storage"
        - "      amazon.aws.s3_object:"
        - "        aws_access_key: \"{{ OBJECTSTORE_S3_KEY_decrypt.decrypted_data.plaintext | b64decode | trim }}\""
        - "        aws_secret_key: \"{{ OBJECTSTORE_S3_SECRET_decrypt.decrypted_data.plaintext | b64decode | trim }}\""
        - "        endpoint_url: \"https://{{ objectstore_s3_hostname }}\""
        - "        region: \"{{ objectstore_s3_region }}\""
        - "        name: \"{{ objectstore_s3_bucketname }}\""
        - "        object: \"{{ '{{ item }}' }}_backup.tar.gz\""
        - "        src: \"{{ project_directory }}/{{ '{{ item }}' }}_backup.tar.gz\""
        - "        mode: put"
        - "      with_items: "
        - "        - mount "
        - "   "

    - name: Clear service and timer files
      ansible.builtin.file:
        path: "/etc/systemd/system/mount-backup.{{ item }}"
        state: absent
      with_items:
        - service
        - timer

    - name: mount backup systemd timer
      ansible.builtin.blockinfile:
        path: /etc/systemd/system/mount-backup.timer
        create: true
        owner: root
        group: root
        mode: '0644'
        block: |
          [Unit]
          Description=Archives and copies mount_application and mount_database directories to cloud storage
          [Timer]
          OnBootSec=60min
          OnUnitActiveSec=12h
          Unit=mount-backup.service
          [Install]
          WantedBy=multi-user.target

    - name: mount backup systemd service
      ansible.builtin.blockinfile:
        path: /etc/systemd/system/mount-backup.service
        create: true
        owner: root
        group: root
        mode: '0644'
        block: |
          [Unit]
          Description=Archives and copies mount_application and mount_database directories to cloud storage
          After=network.target
          [Service]
          ExecStart=/usr/local/bin/ansible-playbook {{ project_directory }}/mount-backup.yml >> /var/log/mount-backup.log
          Type=simple
          Restart=no
          [Install]
          WantedBy=multi-user.target

    - name: mount Backup start/enable
      ansible.builtin.systemd:
        name: "{{ item }}"
        state: started
        enabled: true
        daemon_reload: true
      with_items:
        - mount-backup.timer
        - mount-backup.service
# --------------------------------
    - name: Capture end time
      set_fact:
        end_time: "{{ ansible_facts['date_time']['iso8601'] }}"

    - name: Display end time
      debug:
        msg: "Playbook ended at {{ end_time }}"